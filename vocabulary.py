import re
from gemini_service import GeminiService
from database import Database


class Vocabulary:
    def __init__(self):
        self.gemini = GeminiService()
        self.db = Database()
        self.current_words = {}  # –•—Ä–∞–Ω–∏–º —Ç–µ–∫—É—â–∏–µ —Å–ª–æ–≤–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    
    def parse_vocabulary_response(self, response, topic):
        """–ü–∞—Ä—Å–∏—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –æ—Ç Gemini –∏ –∏–∑–≤–ª–µ—á—å —Å–ª–æ–≤–∞"""
        words = []

        word_blocks = re.split(r'–°–õ–û–í–û\s*\d+\s*:', response, flags=re.IGNORECASE)
        
        for block in word_blocks[1:]:
            if not block.strip():
                continue
            
            try:
                word_data = self.parse_word_block(block)
                if word_data:
                    words.append(word_data)
            except Exception:
                continue
        
        # –ï—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, –ø—Ä–æ–±—É–µ–º fallback
        if len(words) < 3:
            words = self.fallback_parse(response)
        
        if words:
            return {
                "topic": topic,
                "words": words
            }
        return None
    
    def parse_word_block(self, block):
        """–ü–∞—Ä—Å–∏—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–π –±–ª–æ–∫ —Å–ª–æ–≤–∞"""
        lines = block.strip().split('\n')
        
        word = ""
        transcription = ""
        translation = ""
        example_en = ""
        example_ru = ""
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # –ò—â–µ–º –∞–Ω–≥–ª–∏–π—Å–∫–æ–µ —Å–ª–æ–≤–æ
            eng_match = re.match(r'^(?:–ê–Ω–≥–ª–∏–π—Å–∫–æ–µ|English|Word)\s*:\s*(.+)', line, re.IGNORECASE)
            if eng_match:
                word = eng_match.group(1).strip()
                continue
            
            # –ò—â–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
            trans_match = re.match(r'^(?:–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è|Transcription)\s*:\s*(.+)', line, re.IGNORECASE)
            if trans_match:
                transcription = trans_match.group(1).strip()
                continue
            
            # –ò—â–µ–º –ø–µ—Ä–µ–≤–æ–¥
            transl_match = re.match(r'^(?:–ü–µ—Ä–µ–≤–æ–¥|Translation)\s*:\s*(.+)', line, re.IGNORECASE)
            if transl_match:
                translation = transl_match.group(1).strip()
                continue
            
            # –ò—â–µ–º –ø—Ä–∏–º–µ—Ä –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º
            ex_en_match = re.match(r'^(?:–ü—Ä–∏–º–µ—Ä EN|Example EN|English example)\s*:\s*(.+)', line, re.IGNORECASE)
            if ex_en_match:
                example_en = ex_en_match.group(1).strip()
                continue
            
            # –ò—â–µ–º –ø—Ä–∏–º–µ—Ä –Ω–∞ —Ä—É—Å—Å–∫–æ–º
            ex_ru_match = re.match(r'^(?:–ü—Ä–∏–º–µ—Ä RU|Example RU|Russian example)\s*:\s*(.+)', line, re.IGNORECASE)
            if ex_ru_match:
                example_ru = ex_ru_match.group(1).strip()
                continue
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —É –Ω–∞—Å –µ—Å—Ç—å –º–∏–Ω–∏–º—É–º —Å–ª–æ–≤–æ –∏ –ø–µ—Ä–µ–≤–æ–¥
        if word and translation:
            return {
                "word": word,
                "transcription": transcription if transcription else "[-]",
                "translation": translation,
                "example_en": example_en if example_en else f"Example with {word}.",
                "example_ru": example_ru if example_ru else ""
            }
        
        return None
    
    def fallback_parse(self, response):
        """–ó–∞–ø–∞—Å–Ω–æ–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞ - –±–æ–ª–µ–µ –≥–∏–±–∫–∏–π"""
        words = []
        
        # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ç–∏–ø–∞ "—Å–ª–æ–≤–æ - –ø–µ—Ä–µ–≤–æ–¥" –∏–ª–∏ "—Å–ª–æ–≤–æ [—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è] - –ø–µ—Ä–µ–≤–æ–¥"
        # –ü–∞—Ç—Ç–µ—Ä–Ω 1: word [transcription] - translation
        pattern1 = r'(\w+)\s*(\[.+?\])?\s*[-‚Äì‚Äî]\s*([^\n]+)'
        
        matches = re.findall(pattern1, response)
        
        for match in matches:
            if len(match) >= 3:
                word = match[0].strip()
                transcription = match[1].strip() if match[1] else "[-]"
                translation = match[2].strip()
                
                # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞
                if len(word) > 1 and not word.lower() in ['the', 'a', 'an', 'is', 'are']:
                    words.append({
                        "word": word,
                        "transcription": transcription,
                        "translation": translation,
                        "example_en": f"{word.capitalize()} is a useful word.",
                        "example_ru": ""
                    })
        
        # –ï—Å–ª–∏ –ø–∞—Ç—Ç–µ—Ä–Ω 1 –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, –∏—â–µ–º —Å–ø–∏—Å–∫–∏
        if len(words) < 3:
            # –ò—â–µ–º –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏: "1. word - translation"
            pattern2 = r'\d+[\.\)]\s*(\w+)\s*[-‚Äì‚Äî]\s*([^\n]+)'
            matches2 = re.findall(pattern2, response)
            
            for match in matches2:
                if len(match) >= 2:
                    word = match[0].strip()
                    translation = match[1].strip()
                    
                    if len(word) > 1:
                        words.append({
                            "word": word,
                            "transcription": "[-]",
                            "translation": translation,
                            "example_en": f"{word.capitalize()} is a useful word.",
                            "example_ru": ""
                        })
        
        return words
    
    def generate_words(self, topic, number_of_words=10):
        """–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å–ª–æ–≤–∞ –ø–æ —Ç–µ–º–µ"""
        response = self.gemini.generate_vocabulary(topic, number_of_words)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –æ—à–∏–±–∫—É API
        if response.startswith("GEMINI_ERROR:"):
            return False, response.replace("GEMINI_ERROR: ", "")
        
        # –ü–∞—Ä—Å–∏–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç
        vocabulary_data = self.parse_vocabulary_response(response, topic)
        
        if vocabulary_data and vocabulary_data.get('words'):
            return True, vocabulary_data
        else:
            return False, f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Å–ª–æ–≤–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑. –û—Ç–≤–µ—Ç: {response[:300]}..."
    
    def save_words(self, user_id, vocabulary_data):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–ª–æ–≤–∞ –≤ –ë–î"""
        if 'words' in vocabulary_data:
            self.db.save_vocabulary(
                user_id,
                vocabulary_data.get('topic', 'Unknown'),
                vocabulary_data['words']
            )
            self.current_words[user_id] = vocabulary_data
            return True
        return False
    
    def get_current_words(self, user_id):
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–µ —Å–ª–æ–≤–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        return self.current_words.get(user_id)
    
    def format_words_for_display(self, vocabulary_data):
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–ª–æ–≤–∞ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        if not vocabulary_data or 'words' not in vocabulary_data:
            return "–°–ª–æ–≤–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
        
        text = f"üìö –¢–µ–º–∞: {vocabulary_data.get('topic', 'Unknown')}\n\n"
        
        for i, word in enumerate(vocabulary_data['words'], 1):
            text += f"{i}. {word.get('word', '')} [{word.get('transcription', '')}]\n"
            text += f"   –ü–µ—Ä–µ–≤–æ–¥: {word.get('translation', '')}\n"
            text += f"   –ü—Ä–∏–º–µ—Ä: {word.get('example_en', '')}\n"
            if word.get('example_ru'):
                text += f"   {word.get('example_ru', '')}\n"
            text += "\n"
        
        return text
    
    def format_words_compact(self, vocabulary_data):
        """–ö–æ–º–ø–∞–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ (–µ—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ)"""
        if not vocabulary_data or 'words' not in vocabulary_data:
            return "–°–ª–æ–≤–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
        
        text = f"üìö –¢–µ–º–∞: *{vocabulary_data.get('topic', 'Unknown')}*\n\n"
        
        for i, word in enumerate(vocabulary_data['words'], 1):
            text += f"*{i}.* {word.get('word', '')} [{word.get('transcription', '')}]\n"
            text += f"_{word.get('translation', '')}_\n"
            if word.get('example_en'):
                text += f"üá¨üáß {word.get('example_en', '')}\n"
            if word.get('example_ru'):
                text += f"üá∑üá∫ {word.get('example_ru', '')}\n"
            text += "\n"
            
            # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–º, –¥–µ–ª–∞–µ–º —Ä–∞–∑–±–∏–≤–∫—É
            if len(text) > 3000:
                remaining = vocabulary_data['words'][i:]
                if remaining:
                    text += f"\n... –∏ –µ—â—ë {len(remaining)} —Å–ª–æ–≤"
                break
        
        return text
    
    def get_user_vocabulary_history(self, user_id):
        """–ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –∏–∑—É—á–µ–Ω–Ω—ã—Ö —Å–ª–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        return self.db.get_user_vocabulary(user_id)